{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVeMa 2018\n",
    "\n",
    "![logo](assets/logo.jpg \"Logo\")\n",
    "\n",
    "- Instructor: Žiga Emeršič.\n",
    "\n",
    "- Authors: \n",
    "    - Saúl Calderón, Martín Solís, Ángel García, Blaž Meden, Felipe Meza, Juan Esquivel\n",
    "    - Mauro Méndez, Manuel Zumbado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "Supervised learning can happen when we have both:\n",
    "* independent attribute values or input variables $(X)$ and\n",
    "* dependent attribute or output variables $(y)$.\n",
    "\n",
    "We can then use various algorithms to derive the mapping function from the input to the output, defined as:\n",
    "\n",
    "$$y = f(X)$$\n",
    "\n",
    "What we do during training is that we constanly observe and compare predictions and ground-truth labels or values. $y$ maps the values of the independent variable to the dependent, with the error $\\epsilon_i$. So,\n",
    "\n",
    "$$ y_i = f(\\vec{x_i}) + \\epsilon_i $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "First we do feature selection, and based on that we build (train) a decision tree.\n",
    "\n",
    "We can measure attribute purity with\n",
    "* information gain, Gain-ratio,\n",
    "<!--* distance measure, weight of\n",
    "evidence, -->\n",
    "* minimum description length (MDL),\n",
    "* J-measure, Xi and G statistics,\n",
    "* orthogonality of class distribution vectors (ORT),\n",
    "* Gini-index, Relief, ReliefF, etc.\n",
    "\n",
    "Let us do an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbor\n",
    "\n",
    "An object is classified by a majority vote of its neighbours.\n",
    "\n",
    "Object is being assigned to the class most common among its k\n",
    "nearest neighbors,\n",
    "\n",
    "k is a positive integer and its typically small.\n",
    "\n",
    "If k = 1, then the object is simply assigned to the class of that single\n",
    "nearest neighbor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "A Support Vector Machine (SVM) model is a representation of the\n",
    "examples as points in space, mapped so that the examples of the\n",
    "separate categories are divided by a clear gap that is as wide as\n",
    "possible. We can define training as the maximization of the margin on the hyperplane. The hyperplane enables us to model non-linear data in a linear problem space.\n",
    "\n",
    "New examples are then mapped into that same space and predicted\n",
    "to belong to a category based on which side of the gap they fall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "An Artificial Neural Network (ANN) is based on a collection of\n",
    "connected units or nodes called artificial neurons (a simplified version\n",
    "of biological neurons in brain).\n",
    "\n",
    "Each connection (a simplified version of a synapse) between artificial\n",
    "neurons can transmit a signal from one to another.\n",
    "\n",
    "An artificial neuron that receives the signal can process its value and\n",
    "then forwards the result to the artificial neurons connected to it.\n",
    "\n",
    "http://playground.tensorflow.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "\n",
    "Convolutional neural networks are a part of the so-called deep neural networks. The main difference between the traditional (deep) neural networks is that they perform convolutions and are therefore ideal for images and other data where row-column order is important.\n",
    "\n",
    "For in-depth understanding of Convolutional neural networks we recommend: http://cs231n.github.io/\n",
    "\n",
    "In the recent years CNN present state-of-the-art in recognition, object detection\n",
    "and other computer-vision tasks.\n",
    "\n",
    "However, as opposed to the classical approaches where underlying principles are\n",
    "well understood (think about an arbitrary feature extractor or some classification\n",
    "model), here we get a black-box solution that ''just works''. There is no explanation of the decisions. Similarly how humans have problems explaining e.g. \"what a char is\".\n",
    "\n",
    "Some types of layers:\n",
    "* Convolution Layer (no. of feature matrices, size of the matrices)\n",
    "* Pooling Layer (window size, step)\n",
    "* REctified Linear Units (ReLU) Layer\n",
    "* Fully Connected Layer (no. of neurons)\n",
    "\n",
    "An architecture consists of the definition of the elements in the brackets above, and the number, and the\n",
    "order of layers compose the architecture of the CNN.\n",
    "\n",
    "<img src=\"files/filters.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "Let's do the actual calculation!\n",
    "\n",
    "<img src=\"files/x-o-examples.png\" width=\"50%\">\n",
    "\n",
    "<img src=\"files/cnn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So ... how do we order \"those\" layers?\n",
    "\n",
    "<img src=\"files/karpathy.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do CNNs learn?\n",
    "\n",
    "Back-propagation is used to set weights:\n",
    "* Errors are calculated based on ground-truths and the outputs of the fully\n",
    "connected layer. We measure our unhappiness with outcomes such as this one\n",
    "with a loss function (or sometimes also referred to as the cost function or the\n",
    "objective).\n",
    "* For each feature pixels weight is increased and decreased – the new prediction\n",
    "is then again evaluated.\n",
    " _How do we know whether to increase of decrease the weight, and for how\n",
    "much? Gradient descent, of course!_\n",
    "* When we are satisfied with the weights (the errors reach the satisfyingly low values) the learning process is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again to the Overfitting Problem ...\n",
    "\n",
    "What are our options?\n",
    "\n",
    "<img src=\"files/augmentation.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The classical pipeline of the classification\n",
    "\n",
    "An example of the classification pipeline through ear recognition. Let us draw the pipeline in more detail and discuss the components we need.\n",
    "\n",
    "<img src=\"files/pipeline.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: *Saul Calderon, Angel García, Blaz Meden, Ziga Emersic, Felipe Meza, Juan Esquivel, Martín Solís, Mauro Mendez, Manuel Zumbado*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
